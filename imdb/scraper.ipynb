{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a31921",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "#===============================================================================================================\n",
    "\n",
    "#============================================= SELENIUM ==================================================\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.imdb.com/')\n",
    "#driver.maximize_window()\n",
    "\n",
    "\n",
    "dropdown = driver.find_element(By.CLASS_NAME, 'ipc-icon--arrow-drop-down')\n",
    "dropdown.click()\n",
    "\n",
    "# make selenium wait for 2 seconds before clicking on the advanced search btn\n",
    "time.sleep(2)\n",
    "\n",
    "# advanced search logic\n",
    "element = driver.find_element(By.LINK_TEXT, 'Advanced Search')\n",
    "element.click()\n",
    "\n",
    "# click on the advanced title search\n",
    "adv_title = driver.find_element(By.LINK_TEXT, 'Advanced Title Search')\n",
    "adv_title.click()\n",
    "\n",
    "# select feature film\n",
    "feature_film = driver.find_element(By.ID, 'title_type-1')\n",
    "feature_film.click()\n",
    "\n",
    "# select tv_movie\n",
    "tv_movie = driver.find_element(By.ID, 'title_type-2')\n",
    "tv_movie.click()\n",
    "\n",
    "# input min date\n",
    "min_date = driver.find_element(By.NAME, 'release_date-min')\n",
    "min_date.click()\n",
    "min_date.send_keys('1990')\n",
    "\n",
    "# input max date\n",
    "max_date = driver.find_element(By.NAME, 'release_date-max')\n",
    "max_date.click()\n",
    "max_date.send_keys('2022')\n",
    "\n",
    "# rating min\n",
    "rating_min = driver.find_element(By.NAME, 'user_rating-min')\n",
    "rating_min.click()\n",
    "dropdown_2 = Select(rating_min)\n",
    "dropdown_2.select_by_visible_text('1.0')\n",
    "\n",
    "# rating max\n",
    "rating_max = driver.find_element(By.NAME, 'user_rating-max')\n",
    "rating_max.click()\n",
    "dropdown_3 = Select(rating_max)\n",
    "dropdown_3.select_by_visible_text('10')\n",
    "\n",
    "# oscar nominated \n",
    "oscar_nominated = driver.find_element(By.ID, 'groups-7')\n",
    "oscar_nominated.click()\n",
    "\n",
    "# select color\n",
    "color = driver.find_element(By.ID, 'colors-1')\n",
    "color.click()\n",
    "\n",
    "# select language\n",
    "language = driver.find_element(By.NAME, 'languages')\n",
    "dropdown_4 = Select(language)\n",
    "dropdown_4.select_by_visible_text('English')\n",
    "\n",
    "# select page's result\n",
    "results_count = driver.find_element(By.ID, 'search-count')\n",
    "dropdown_5 = Select(results_count)\n",
    "dropdown_5.select_by_index(2)\n",
    "\n",
    "# click on the search btn\n",
    "\n",
    "search_btn = driver.find_element(By.XPATH, '(//button[@type=\"submit\"])[2]')\n",
    "search_btn.click()\n",
    "\n",
    "# current\n",
    "current_url = driver.current_url\n",
    "\n",
    "time.sleep(5)\n",
    "#===============================================================================================================\n",
    "\n",
    "#============================================= BEAUTIFUL SOUP ==================================================\n",
    "\n",
    "\n",
    "# create an empty list to store the data for all pages\n",
    "all_data = []\n",
    "\n",
    "# create a loop to go through all the pages\n",
    "for page_num in range(1, 5): # replace \"5\" with the number of pages you want to scrape\n",
    "    # modify the URL to include the \"&start=\" parameter with the appropriate value\n",
    "    time.sleep(5)\n",
    "    url = current_url + \"&start=\" + str((page_num - 1) * 250)\n",
    "    print(url)\n",
    "\n",
    "    # get request\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # soup object\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    list_items = soup.find_all('div', {'class':'lister-item'})\n",
    "\n",
    "    # get all the titles\n",
    "    movie_title = [result.find('h3').find('a').text for result in list_items]\n",
    "\n",
    "    # get all the  years\n",
    "    year = [result.find('h3').find('span', {'class':'lister-item-year'}).text.replace('(', '').replace(')', '') for result in list_items]\n",
    "\n",
    "    # get all the genres\n",
    "    genre = [result.find('span', {'class':'genre'}).text.replace('\\n', '').strip() for result in list_items]\n",
    "\n",
    "    # get all the ratings\n",
    "    rating = [result.find('div', {'class':'ratings-imdb-rating'}).find('strong').text for result in list_items]\n",
    "\n",
    "    # get all the descriptions\n",
    "    description = [result.find('div', {'class':'lister-item-content'}).find_all('p')[1].text.strip() for result in list_items]\n",
    "\n",
    "    # get all the durations\n",
    "    duration = [result.find('span', {'class':'runtime'}).text for result in list_items]\n",
    "\n",
    "    # get all the directors\n",
    "    director = [result.find('p', {'class': ''}).find('a').text for result in list_items]\n",
    "\n",
    "    # get all the stars\n",
    "    cast_tags = [result.find('p', {'class': ''}).find_all('a')[1:] for result in list_items]\n",
    "    cast = [[tag.get_text() for tag in movie_cast] for movie_cast in cast_tags]\n",
    "\n",
    "    # get all the grosses\n",
    "    gross = [result.find('span', {'name':'nv'}).text for result in list_items]\n",
    "\n",
    "    image_urls = [img_tag.attrs['loadlate'] for result in list_items\n",
    "                  for img_div in [result.find('div', {'class': 'lister-item-image'})]\n",
    "                  for img_tag in [img_div.find('img')]\n",
    "                  if img_div and img_tag and 'loadlate' in img_tag.attrs\n",
    "                  and img_tag.attrs['loadlate'].endswith('.jpg')]\n",
    "\n",
    "    # pandas\n",
    "    imdb_df = pd.DataFrame({'Movie title': movie_title, 'Year': year,\n",
    "                            'Genre': genre, 'Rating': rating,\n",
    "                            'Description': description, 'Duration': duration,\n",
    "                            'Director': director, 'Cast': cast, 'Gross': gross,\n",
    "                            'Images': image_urls})\n",
    "\n",
    "\n",
    "    all_data.append(imdb_df)\n",
    "\n",
    "# combine all the dataframes\n",
    "final_df = pd.concat(all_data)\n",
    "final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e2a21f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
